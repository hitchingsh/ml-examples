{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language_Translation_Using_the_T5_Model_And_HuggingFace_Framework.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXGZC40ZzV0x"
      },
      "source": [
        "# Language Translation Using the T5 Model and HuggingFace Framework\n",
        "\n",
        "Translates English to German with high accuracy in only a few lines of code by using the HuggingFace Framework. \n",
        "\n",
        "This notebook shows both the highest level abstraction with pipelines and a slightly lower level API where we create the model and tokenizer before doing the translations.\n",
        "\n",
        "This example use the same test sentences I used in my 2nd Coursera class capstone project plus a bonus complex sentence.  All examples below were confirmed to have been correctly translated by reverse translating the results using Google Translate.\n",
        "\n",
        "Uses the T5 Model (Text-to-Text Transfer Transformer)\n",
        "https://arxiv.org/abs/1910.10683\n",
        "\n",
        "For T5 to be able to operate on all NLP tasks, it transforms them into text-to-text problems by using specific prefixes: “summarize: ”, “question: ”, “translate English to German: ” and so forth. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMa9Z09E0x_-"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3XGY_30zrHo"
      },
      "source": [
        "from transformers import pipeline\n",
        "translator = pipeline(\"translation_en_to_de\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldT_pwIC23Qd"
      },
      "source": [
        "english_strings = [\"I need my key.\", \"I have won.\", \"take a bus\", \"Do you know that?\", \"That'll be fun.\", \"You can fly non-stop from San Francisco to Munich on United Airlines but its a long flight\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luPpQ4Jnz5XZ",
        "outputId": "d994070b-d1d1-4b09-a47b-0a9a480fffe7"
      },
      "source": [
        "for english_string in english_strings:\n",
        "  print(f'English: {english_string}')\n",
        "  german_string = translator(english_string)[0]['translation_text']\n",
        "  print(f'German: {german_string}\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: I need my key.\n",
            "German: Ich brauche meinen Schlüssel.\n",
            "\n",
            "English: I have won.\n",
            "German: Ich habe gewonnen.\n",
            "\n",
            "English: take a bus\n",
            "German: Bus nehmen\n",
            "\n",
            "English: Do you know that?\n",
            "German: Wissen Sie das?\n",
            "\n",
            "English: That'll be fun.\n",
            "German: Das wird Spaß machen.\n",
            "\n",
            "English: You can fly non-stop from San Francisco to Munich on United Airlines but its a long flight\n",
            "German: Sie können mit United Airlines von San Francisco nach München fliegen, aber es ist ein langer Flug.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4XZu3Cy118M"
      },
      "source": [
        "Going one level lower in the HuggingFace API in case we needed more control including the ability to specify the model, tokenizer and if needed the config.  Note, we are using T5 summarization and a special feature to do translation. \n",
        "\n",
        "The following uses PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RTl0S8y03G0",
        "outputId": "c8633c31-b45a-4173-d7d5-0565e5e7beb8"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:970: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OXwieh62i5J",
        "outputId": "a86cc653-c392-485f-edd5-2cafa177f296"
      },
      "source": [
        "for english_string in english_strings:\n",
        "  print(f'English: {english_string}')\n",
        "\n",
        "  # Add the T5 specific prefix “translate English to German: “ since this is a generative model\n",
        "  english_string = \"translate English to German:\" + english_string\n",
        "\n",
        "  inputs = tokenizer.encode(english_string, return_tensors=\"pt\")\n",
        "\n",
        "  # Overriding PreTrainedModel.generate() default config, e.g. max_length\n",
        "  outputs = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "  german_string = tokenizer.decode(outputs[0]).lstrip('<pad>').rstrip('</s>')\n",
        "  print(f'German: {german_string}\\n')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: I need my key.\n",
            "German:  Ich brauche meinen Schlüssel.\n",
            "\n",
            "English: I have won.\n",
            "German:  Ich habe gewonnen.\n",
            "\n",
            "English: take a bus\n",
            "German:  Bus nehmen\n",
            "\n",
            "English: Do you know that?\n",
            "German:  Wissen Sie das?\n",
            "\n",
            "English: That'll be fun.\n",
            "German:  Das wird Spaß machen.\n",
            "\n",
            "English: You can fly non-stop from San Francisco to Munich on United Airlines but its a long flight\n",
            "German:  Sie können mit United Airlines von San Francisco nach München fliegen, aber es ist ein langer Flug.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JAB7UU28UOr"
      },
      "source": [
        "Same as above except in Tensorflow 2.0.  Notice the differences are trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YONwHkLs5uPw",
        "outputId": "335fd850-4f4c-4037-f8c5-7284e695a81c"
      },
      "source": [
        "from transformers import TFAutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "model = TFAutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_tf_auto.py:814: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYaBZSZ_8jtZ",
        "outputId": "94b20a7f-008d-4ebb-96c5-fd411bd734de"
      },
      "source": [
        "for english_string in english_strings:\n",
        "  print(f'English: {english_string}')\n",
        "\n",
        "  # Add the T5 specific prefix “translate English to German: “ since this is a generative model\n",
        "  english_string = \"translate English to German:\" + english_string\n",
        "\n",
        "  inputs = tokenizer.encode(english_string, return_tensors=\"tf\")\n",
        "\n",
        "  # Overriding PreTrainedModel.generate() default config, e.g. max_length\n",
        "  outputs = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "  german_string = tokenizer.decode(outputs[0]).lstrip('<pad>').rstrip('</s>')\n",
        "  print(f'German: {german_string}\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: I need my key.\n",
            "German:  Ich brauche meinen Schlüssel.\n",
            "\n",
            "English: I have won.\n",
            "German:  Ich habe gewonnen.\n",
            "\n",
            "English: take a bus\n",
            "German:  Bus nehmen\n",
            "\n",
            "English: Do you know that?\n",
            "German:  Wissen Sie das?\n",
            "\n",
            "English: That'll be fun.\n",
            "German:  Das wird Spaß machen.\n",
            "\n",
            "English: You can fly non-stop from San Francisco to Munich on United Airlines but its a long flight\n",
            "German:  Sie können mit United Airlines von San Francisco nach München fliegen, aber es ist ein langer Flug.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}